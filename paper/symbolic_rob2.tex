\documentclass{article}

\usepackage{graphicx} % more modern
\usepackage{subfigure} 
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}


% For citations
\usepackage{natbib}

% For algorithms
\usepackage{comment}
\usepackage{framed}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
%\usepackage{algorithmicx}
%\usepackage{algpseudocode}

\usepackage{hyperref}

\allowdisplaybreaks

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}

\usepackage[accepted]{icml2012}  % XXX : just set temporarly to print out authors corretly.

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document} 

\icmltitle{Efficient Formulae Discovery for Polynomial Expressions}

\icmlauthor{Wojciech Zaremba}{zaremba@cs.nyu.edu}
\icmlauthor{Karol Kurach}{kkurach@google.com}
\icmlauthor{Rob Fergus}{fergus@cs.nyu.edu}


\icmlkeywords{machine learning, optimization, automatic theorem proving, RBM, NP, Boltzmann machine}

\vskip 0.3in


\begin{abstract} We present an approach based on attributive grammars
  for automatically discovering efficient ways to compute polynomial
<<<<<<< HEAD
  expressions. Our method can handle expressions with thousands of
  terms, otherwise intractible
  for humans. We use the approach to
  compute a Taylor series approximation for the partition function of
  a restricted Boltzmann machine (RBM). We show how to compute a 4th
  order approximation in polynomial time, compared to exponential time
  of the naive approach. More generally, our method can be considered a
  formal system to which machine learning methods such as
  probabilistic programming can be applied. 
\end{abstract} 

\section{Introduction} \label{introduction} 

Progress in some branches of
mathematics might be restricted by size of symbolic derivations that human can
handle.  Mathematicians can deal with expressions having dozens of
variables but would struggle to discover useful relations between hundreds or
thousands of variables. We will show how the task of finding equivalent
mathematical expressions can be automated. Our focus is on finding equivalent
mathematical formulas (i.e.~which give an identical numerical result),
but are faster to compute than the original expression. The definition
of faster can be either (i) the number of operations or (ii) the computational time
for particular hardware.

We propose deterministic, grammar based framework, which discovers relations between
multi-variable polynomial expressions. First, we construct an attribute grammar
-- a context-free grammar extended to contain set of attributes, introduced by
Donald Knuth \cite{knuth1968semantics}. To define the search space we use a set
context-free grammar rules representing admissible operations. By representing
the cost of every operation as a synthetized attribute (i.e. computed bottom-up from child node attributes)
we can search for formula with low time complexity.
Through linear combination of grammar elements, we find solution to desired 
expressions that we want to compute. Finally, we
show that this computation solution can be further speed up by use of standard
techniques of optimization in compiler domain. We show the power of the
approach by deriving closed form, $O(n^3)$ time solutions for a 
a Taylor series approximation to the partition
function of an RBM. These close form solutions oppose
the widespread belief that accurately computation of the partition function requires
an exponential number of elements.


Finally, we can regard the set of generated rules as a small axiomatic system.
The presented algorithm is deterministic, and provably runs in finite
time. ROB:????
We are excited about using machine learning for automatic reasoning, and
this subset of mathematics seems to be perfect fit for testing automatic reasoning systems.
Usually, axiomatic systems like number theory, set theory, or topology have very small
number of axioms, but their application to terms might be complex. Proofs
for such systems are difficult to represent in software, and there is no
baseline algorithms which could brute force proof by iterating over all of them in reasonable finite time.
Where in the contrary, presented here axiomatic system has very simple representation
in software, and this paper presents brute force algorithm to find proofs. 
Surprisingly, even brute force algorithm is able to find new more efficient,
computational expressions for expressions that we use.

By the time of publication we are going to release code.
=======
  expressions. Our method can handle expressions which are intractible
  for humans with thousands of
  terms. We apply the approach to
  computing a Taylor series approximation of the partition function of
  a restricted Boltzmann machine (RBM). We show how to compute a 5th
  order approximation in polynomial time, compared to exponential time
  of the naive approach. Moreover, we apply it to the simple
  matrix expressions like $\sum AB$ (where $A$, $B$ are matrices) and it finds
  derivation with lower computation complexity ($O(n^2)$ instead of $O(n^3$)).
>>>>>>> a2bbba9be56bf4455e7f9f8495bfb4af6a52b4b0


  Finally, we look on our method as a small axiomatic system. Where our derivations
  are proofs. Method presented here is a brute force search over
  proofs in this formal system. Goal is to bring automatic theorem proving 
  to the field of machine learning, and apply smarted techniques than brute force
  to find proofs. We believe, that tackling symbolic systems problems with machine learning
  is crucial step in machine perception after computer vision, and natural language processing.
  Moreover, it is very difficult problem from structural prediction perspective (due to the rich structure).

\end{abstract} 

\section{Introduction} \label{introduction} 
\input{introduction}

\section{Related work} \label{relatedwork}
\input{related_work}

\section{Terminology}
\input{terminology}

\section{Admissible computation as a grammars}\label{sec:grammars}
\input{admissible_computation}


\section{Partition function of RBM} \label{partitionfunction}
\input{partition_function}

\section{Experiments}
\input{experiments}

\section{Computation generalization}\label{agenda}
\input{generalization}

\section{Conjecture on hardness of partition function approximation}
\input{conjecture}

\section{Discussion and future work}
\input{discussion}


\nocite{*}
\bibliography{bibliography}
\bibliographystyle{icml2012}

\end{document} 

