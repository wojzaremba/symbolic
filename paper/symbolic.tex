\documentclass{article}

\usepackage{graphicx} % more modern
\usepackage{subfigure} 
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}


% For citations
\usepackage{natbib}

% For algorithms
\usepackage{comment}
\usepackage{framed}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
%\usepackage{algorithmicx}
%\usepackage{algpseudocode}

\usepackage{hyperref}

\allowdisplaybreaks

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}

\usepackage[accepted]{icml2012}  % XXX : just set temporarly to print out authors corretly.

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document} 

\icmltitle{Efficient Formulae Discovery for Polynomial Expressions}

\icmlauthor{Wojciech Zaremba}{zaremba@cs.nyu.edu}
\icmlauthor{Karol Kurach}{kkurach@google.com}
\icmlauthor{Rob Fergus}{fergus@cs.nyu.edu}


\icmlkeywords{machine learning, optimization, automatic theorem proving, RBM, NP, Boltzmann machine}

\vskip 0.3in


\begin{abstract} We present an approach based on attributive grammars
  for automatically discovering efficient ways to compute polynomial
  expressions. Our method can handle expressions which are intractible
  for humans with thousands of
  terms. We apply the approach to
  computing a Taylor series approximation of the partition function of
  a restricted Boltzmann machine (RBM). We show how to compute a 5th
  order approximation in polynomial time, compared to exponential time
  of the naive approach. Moreover, we apply it to the simple
  matrix expressions like $\sum AB$ (where $A$, $B$ are matrices) and it finds
  derivation with lower computation complexity ($O(n^2)$ instead of $O(n^3$)).


  Finally, we look on our method as a small axiomatic system. Where our derivations
  are proofs. Method presented here is a brute force search over
  proofs in this formal system. Goal is to bring automatic theorem proving 
  to the field of machine learning, and apply smarted techniques than brute force
  to find proofs. We believe, that tackling symbolic systems problems with machine learning
  is crucial step in machine perception after computer vision, and natural language processing.
  Moreover, it is very difficult problem from structural prediction perspective (due to the rich structure).

\end{abstract} 

\section{Introduction} \label{introduction} 
\input{introduction}

\section{Related work} \label{relatedwork}
\input{related_work}

\section{Terminology}
\input{terminology}

\section{Admissible computation as a grammars}\label{sec:grammars}
\input{admissible_computation}


\section{Partition function of RBM} \label{partitionfunction}
\input{partition_function}

\section{Experiments}
\input{experiments}

\section{Computation generalization}\label{agenda}
\input{generalization}

\section{Conjecture on hardness of partition function approximation}
\input{conjecture}

\section{Discussion and future work}
\input{discussion}


\nocite{*}
\bibliography{bibliography}
\bibliographystyle{icml2012}

\end{document} 

