\section{Conjecture on Hardness of Partition Function Approximation}
Approximation of the partition function is one of the most important problems
in machine learning.  Our framework gives a potential solution to this
issue, as well an intuition about how hard this problem is. This
section assumes what we have observed for $g(x \rightarrow x^k, W)$
holds true for powers beyond $k=6$, and presents conjectures relating to the hardness of
approximation of the partition function. Unfortunately, thus far we
have not been able to prove, or disprove these conjectures.
\begin{conjecture}
  $g(x \rightarrow x^k, W)$ consists of a linear combination of terms
  for a matrix $W$, generated by use of rules defined in Figure
  \ref{fig:rules2} and \ref{fig:rules}. Furthermore, the size of the generated grammar up to degree $k$
  grows like $O(\lambda^k)$ for some constant $\lambda$.
\label{simple}
\end{conjecture}

The following corollary and lemma assumes that Conjecture \ref{simple} is valid.

\begin{corollary}
	$g(x \rightarrow x^k, W)$
	can be computed in exponential time in $k$, but in $O(n^3)$ time with respect to size of $W$ ($W$ is of size $n \times n$).
\end{corollary}

\begin{lemma}
	For $x < C$, $e^x$ can be approximated up to $\epsilon$ accuracy in log scale with $\frac{Ce}{\epsilon}$ terms. 
\end{lemma}
\begin{proof}

For every $x < C$ there exists $u < x$, such that:  
\begin{align*}
	e^x = 1 + \frac{x}{1!} + \frac{x^2}{2!} + \dots + \frac{x^{k - 1}}{(k - 1)!} + \frac{x^k}{k!}e^u
\end{align*}
Using Moiver's formula ($k! \sim [const] * \frac{k^{k + 1/2}}{e^k}$) we get:
\begin{align*}
	|e^x - (1 + \frac{x}{1!} + \frac{x^2}{2!} + \dots + \frac{x^{k - 1}}{(k - 1)!}) | < \frac{C^k}{k!}e^C \\
	\sim \exp(k\log{C} + C - k\log{k} + k) < \epsilon
\end{align*}

To find the number of terms required to approximate with accuracy $\epsilon$, we look for 
the smallest $k$ satisfying: 
\begin{align*}
	k (1 + \log{C} - \log{k}) < \log{\epsilon} - C\\ 
	k (\log{Ce} - \log{k}) < \log{\epsilon} - C
\end{align*}
Let us assume that:
\begin{equation}
\label{eq:eps_ineq}
\log{\epsilon} < -1
\end{equation}
\begin{equation}
\label{eq:c_ineq}
1 - Ce < -C
\end{equation}
These assumptions are valid if $\epsilon$ is small enough, and $C$ is large enough.

For such $\epsilon$ and $C$, and $k > \frac{Ce}{\epsilon}$, the
following inequalities are satisfied:
\begin{align*}
	\frac{Ce}{\epsilon} (\log{Ce} - \log{\frac{Ce}{\epsilon}}) < \log{\epsilon} - C \\
	\frac{Ce}{\epsilon} \log{\epsilon} < \log{\epsilon} - C\\
	C < \log{\epsilon}(1 - \frac{Ce}{\epsilon})
\end{align*}

Using assumption \ref{eq:eps_ineq} we get:
\begin{align*}
  C < -1 * (1 - \frac{Ce}{\epsilon}) \Leftrightarrow 1 - \frac{Ce}{\epsilon} < -C
\end{align*}
Which is true, because of assumption \ref{eq:c_ineq} ($\epsilon < 1 \Rightarrow \frac{Ce}{\epsilon} > Ce$).

This implies that if $max_{v,h}\text{ } v^TWh < C$, we can
approximate the partition function up to $\epsilon$ (in log scale)
by using $k = \frac{Ce}{\epsilon}$ terms of the Taylor series. 
This algorithm assumes Conjecture \ref{simple} has complexity $O(\lambda^{\frac{Ce}{\epsilon}}n^3)$.

\vspace{-5mm}
\end{proof}
\vspace{-5mm}


