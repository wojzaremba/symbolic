\section{Discussion and Future Work}

We have presented an automatic method for discovering efficient way to
compute polynomial expressions. The method itself is novel, and
has broad applications in the marginalization of dropout and
deriving new approximations for RBM partition function. There are three
major directions of future research: 

\begin{enumerate}
  \item Well study properties of approximations for various tasks. Use them to
        train large neural networks.
  \item Extend our method to (i) a richer class of functions
    than polynomials, (ii) a larger set of production rules, (iii) more complex
    objects than matrices (e.g.~tensors). We elaborate on this in
    Section \ref{sec:extend}.
\item Explore real-world applications of this framework on large code databases. 
  It could be used to automatically detect parts of code with expressions that have suboptimal 
  time complexity and replace them with more efficient expressions.
\end{enumerate}


\subsection{Extension of Grammar}
\label{sec:extend}
The presented framework has some limitations, but also can be easily extended. First,
we operate on polynomials instead of generic functions. 
It is quite easy to verify equality of polynomials, but for generic functions it becomes more complex.
For example, if our basis would to include trigonometric functions, then the
framework would have to be aware of many additional identities,
e.g. $\sin^2{x} + \cos^2{x} = 1$, or $2\sin x \cos x = \sin
2x$. Although challenging, we believe it is possible to extend our
framework to handle such cases. 

It is straight forward to extend our framework to matrices of fractional
polynomials instead of matrices of polynomials.  We could
then include productions like matrix inverse and element-wise inverse of
a matrix.  Another direction would be to generalize matrices to arbitrary tensors
for which it is even harder for humans to spot useful relations.

Finally, we are interested in exploiting productions which could discover 
recurrences. This would allow the discovery the fast Fourier transform, or
Strassen's algorithm for fast matrix multiplication. This family of problems is quite broad,
and crucial in computation.


